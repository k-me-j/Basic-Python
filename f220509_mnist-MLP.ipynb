{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc634505-a332-4932-8fcb-4c72d29178a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a19eef-719d-4a80-82a9-f0f603703176",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, train_label), (test_set, test_label) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7acfa2-3cb6-4a1c-b5a1-91ef73631f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_label\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd42cf-bd85-4529-b03e-f4d37c0430cc",
   "metadata": {},
   "source": [
    "# ▶ shape 맞춰주기\n",
    "3차원 못받음 2차원으로 받아들임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09bf861-1420-47d0-b0f4-c55b36ff98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 때 1차원으로 입력했었기 때문. -> 28*28 이미지가 6만장 = 3차원이 되니까 2차원으로 바꿨는데 그게 1차원 6만개였던거야.\n",
    "train_set = train_set.reshape(len(train_set), 784)\n",
    "test_set = test_set.reshape(len(test_set), 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06805d7f-280e-4731-af26-d8e1196b3d72",
   "metadata": {},
   "source": [
    "## ▷ 범주화 = 원핫인코딩 : to_categorical\n",
    "- 원핫인코딩을 하는 이유 : 활성화 함수를 적용하려면 Y값이 0과 1로 이루어져 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86fb0825-9f9c-4398-8025-e0428e9b98cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c151524-80b1-4951-bbe5-41ad237b060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = tf.keras.utils.to_categorical(train_label, 10)\n",
    "test_label = tf.keras.utils.to_categorical(test_label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf29b81f-2243-46eb-8794-3171bf40cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f8e4c-461b-401c-9b71-cd0ca2e52cb6",
   "metadata": {},
   "source": [
    "# ▶ 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107982cc-6d60-40fc-85a3-e8023202a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d46ddec-6387-4344-8f4f-a1ece0ade205",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.add(Dense(512, input_dim=784, activation=\"relu\"))\n",
    "mlp.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dea0df6-d771-434d-923f-50c46fe6562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cad526f-7fde-45f0-8f6c-6c3f3f4824c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(loss=\"categorical_crossentropy\",\n",
    "           optimizer=\"adam\",\n",
    "           metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fedfc1d-86bb-49fb-b793-ef08ba4b2ebe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9914\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9916\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9905\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9918\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9914\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9915\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9924\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9924\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9923\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9920\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9917\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9917\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9904\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9905\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9923\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9923\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9924\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9916\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9925\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9933\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9935\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9924\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9923\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9928\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9928\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9925\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9921\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9929\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9927\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9924\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8727 - accuracy: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8726606369018555, 0.9702000021934509]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCHSIZE = 200\n",
    "\n",
    "mlp.fit(train_set, train_label, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCHSIZE)  # 배치 설정하면 훨씬 빠름\n",
    "\n",
    "mlp.evaluate(test_set, test_label)  # [loss, acc] 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e22a36e-d53e-4c1f-9010-438f61aeae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6369746327400208, 0.968999981880188]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.save(\"./220509_mlp_hd512_e30.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a05bd-1d10-4538-9765-eb9590e661da",
   "metadata": {},
   "source": [
    "# ▶ 저장된 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3123911-75c9-439b-bf6e-26790810dd11",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "path = \"./220509_mlp_hd512_e30.h5\"\n",
    "mlp = load_model(path)\n",
    "acc = mlp.evaluate(test_set, test_label, batch_size=BATCHSIZE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe6982-ed67-4847-a260-c900ebef725d",
   "metadata": {},
   "source": [
    "# ▶ mlp 모델 튜닝으로 accuracy 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadda4a9-2290-4c58-b7a8-a777abc94d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 : 0~255 -> 0~1 범위로 줄여주기\n",
    "train_set = train_set.astype('float64') / 255\n",
    "test_set = test_set.astype('float64') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dd0b354-3b1e-44a0-a8cc-d91a3ae85810",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2620 - accuracy: 0.9243\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9726\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0577 - accuracy: 0.9818\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9866\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0288 - accuracy: 0.9906\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9927\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0174 - accuracy: 0.9943\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9955\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0140 - accuracy: 0.9954\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9970\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0951 - accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09508573263883591, 0.980400025844574]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCHSIZE = 200\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "           optimizer=\"adam\",\n",
    "           metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, train_label, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCHSIZE)  # 배치 설정하면 훨씬 빠름\n",
    "\n",
    "model.evaluate(test_set, test_label)  # [loss, acc] 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be89ab70-1b56-4d43-a882-e9839b680cd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2367 - accuracy: 0.9292\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0917 - accuracy: 0.9716\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0602 - accuracy: 0.9805\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0436 - accuracy: 0.9856\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0345 - accuracy: 0.9887\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.9916\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0189 - accuracy: 0.9938\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0130 - accuracy: 0.9957\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9971\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0065 - accuracy: 0.9977\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0067 - accuracy: 0.9985\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0039 - accuracy: 0.9992\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0071 - accuracy: 0.9982\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1314394325017929, 0.9832000136375427]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCHSIZE = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=784, activation=\"swish\"))\n",
    "model.add(Dense(256, activation=\"swish\"))\n",
    "model.add(Dense(128, activation=\"swish\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "           optimizer=\"adam\",\n",
    "           metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, train_label, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCHSIZE)  # 배치 설정하면 훨씬 빠름\n",
    "\n",
    "model.evaluate(test_set, test_label)  # [loss, acc] 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016f0bd-2afd-4280-8c69-6daed83aa67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCHSIZE = 200\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=784, activation=\"swish\"))\n",
    "model.add(Dense(256, activation=\"swish\"))\n",
    "model.add(Dense(128, activation=\"swish\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "           optimizer=\"adam\",\n",
    "           metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, train_label, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCHSIZE)  # 배치 설정하면 훨씬 빠름\n",
    "\n",
    "model.evaluate(test_set, test_label)  # [loss, acc] 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fde18-2244-45bd-98da-b86e35cd6d12",
   "metadata": {},
   "source": [
    "## ▷ GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb738940-1e39-4351-80a6-12ff7ec40039",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create list of hyperparameters \n",
    "# max_iter = [10, 20]\n",
    "# hidden_layer_sizes = [(512,), (256,), (128,)]\n",
    "\n",
    "# param_grid = {'max_iter': max_iter, 'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "batch_size = [30, 50, 100, 150, 200, 250, 300]\n",
    "epochs = [10, 30, 50, 100]\n",
    "param_grid2 = {'batch_size':batch_size}\n",
    "\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = mlp, \n",
    "                   param_grid = param_grid2, \n",
    "                   scoring = 'accuracy', \n",
    "                   cv = 3,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "result = grid_search.fit(train_set, y_train)\n",
    "results.best_params_, results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb00624-6043-4e95-81e8-9b0dfd990c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "100, 300\n",
    "relu\n",
    "rmsprop, adam\n",
    "98.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e9c363-ea99-4140-8c41-7d60d06b42a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.3188 - accuracy: 0.9003\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1215 - accuracy: 0.9615\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0781 - accuracy: 0.9748\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0554 - accuracy: 0.9823\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0433 - accuracy: 0.9864\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0334 - accuracy: 0.9890\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0262 - accuracy: 0.9911\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0215 - accuracy: 0.9935\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0202 - accuracy: 0.9935\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0156 - accuracy: 0.9952\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0127 - accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0117 - accuracy: 0.9968\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0112 - accuracy: 0.9971\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0078 - accuracy: 0.9981\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0095 - accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0080 - accuracy: 0.9984\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0083 - accuracy: 0.9981\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0087 - accuracy: 0.9983\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9983\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0079 - accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0071 - accuracy: 0.9984\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0068 - accuracy: 0.9988\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0079 - accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0084 - accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0069 - accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.9987\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0067 - accuracy: 0.9991\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0070 - accuracy: 0.9986\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0083 - accuracy: 0.9988\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0072 - accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0082 - accuracy: 0.9989\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0052 - accuracy: 0.9991\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0083 - accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0058 - accuracy: 0.9989\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0058 - accuracy: 0.9989\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0066 - accuracy: 0.9988\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9991\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9993\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0058 - accuracy: 0.9992\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0066 - accuracy: 0.9991\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0051 - accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0056 - accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9991\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9994\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0075 - accuracy: 0.9991\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0050 - accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0060 - accuracy: 0.9991\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0051 - accuracy: 0.9991\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0042 - accuracy: 0.9994\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0031 - accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0044 - accuracy: 0.9994\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0065 - accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9994\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0040 - accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0062 - accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0057 - accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0048 - accuracy: 0.9994\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0062 - accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0037 - accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0031 - accuracy: 0.9996\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0035 - accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0062 - accuracy: 0.9994\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42813608050346375, 0.9824000000953674]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCHSIZE = 300\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, input_dim=784, activation=\"swish\"))\n",
    "model.add(Dense(512, activation=\"swish\"))\n",
    "model.add(Dense(256, activation=\"swish\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "           optimizer=\"rmsprop\",  # adam\n",
    "           metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, train_label, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCHSIZE)  # 배치 설정하면 훨씬 빠름\n",
    "\n",
    "model.evaluate(test_set, test_label)  # [loss, acc] 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e57271c-0a6e-4d32-89e6-6a0ac487b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 1.8458 - accuracy: 0.4187 - val_loss: 1.2026 - val_accuracy: 0.7782\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.1459 - accuracy: 0.6812 - val_loss: 0.7296 - val_accuracy: 0.8299\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.8546 - accuracy: 0.7512 - val_loss: 0.5654 - val_accuracy: 0.8552\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.7221 - accuracy: 0.7825 - val_loss: 0.4856 - val_accuracy: 0.8713\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.6465 - accuracy: 0.8065 - val_loss: 0.4377 - val_accuracy: 0.8819\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.5945 - accuracy: 0.8221 - val_loss: 0.4050 - val_accuracy: 0.8891\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.5554 - accuracy: 0.8347 - val_loss: 0.3808 - val_accuracy: 0.8952\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.5230 - accuracy: 0.8432 - val_loss: 0.3624 - val_accuracy: 0.8998\n",
      "Epoch 9/50\n",
      "533/600 [=========================>....] - ETA: 0s - loss: 0.5009 - accuracy: 0.8495"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_79336/1662922530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m model.fit(train_set, train_label,\n\u001b[0m\u001b[0;32m     17\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100  # 128\n",
    "EPOCHS = 50 # 10\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, activation='relu', input_dim=784))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adagrad',  # rmsprop 98.48, adam 98.35\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set, train_label,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(test_set, test_label))\n",
    "\n",
    "model.evaluate(test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b7e40-e1b5-4c74-987e-d41a2933e320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
