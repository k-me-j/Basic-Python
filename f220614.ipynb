{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0fc4321-317d-42b9-9284-277519f3553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d20575d7-a1fc-49e0-becc-d168909cd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],\n",
    "        [4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b06c7a-d850-493b-889b-17ae2b28c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb2f55-ddde-47fa-83c1-77b31a6232e1",
   "metadata": {},
   "source": [
    "## w, b 데이터 지정\n",
    "- x_train : 6x2 * 2x1(weights) ==> 6x1 + b (bias: 1)\n",
    "- sigmoid(wx+b) ==> if w==0 and b==0 ==> sigmoid(0)  ==> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926975b3-99bb-40d6-97e3-046401906efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.zeros((2,1), requires_grad=True)\n",
    "# w = torch.randn((2,1), requires_grad=True)  # 이렇게 해도 됨\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ff08308-971d-4be9-8f2a-5339575cced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([w,b], lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcd55d21-8bcd-442e-8307-a89bd7b080c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000, cost: 0.019834\n",
      "Epoch  100/1000, cost: 0.018149\n",
      "Epoch  200/1000, cost: 0.016730\n",
      "Epoch  300/1000, cost: 0.015517\n",
      "Epoch  400/1000, cost: 0.014469\n",
      "Epoch  500/1000, cost: 0.013554\n",
      "Epoch  600/1000, cost: 0.012748\n",
      "Epoch  700/1000, cost: 0.012033\n",
      "Epoch  800/1000, cost: 0.011394\n",
      "Epoch  900/1000, cost: 0.010819\n",
      "Epoch 1000/1000, cost: 0.010300\n",
      "w : tensor([[3.8961],\n",
      "        [1.8565]], requires_grad=True)\n",
      "b : tensor([-17.4290], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # 1. Hypothesis 함수 : Forward\n",
    "    # sigmoid function 작성한 것을 import 해서  사용해도 됨\n",
    "    # sigmoid = 1/1+e^(-wx+b) 와 같음\n",
    "    hx = 1 / (1+ torch.exp(-(x_train.matmul(w) + b)))\n",
    "    \n",
    "    # 2. Cost Function 사용\n",
    "    # cost(hx) 1 : -log(h(x))\n",
    "    # cost(hx) 0 : -log(1-h(x))\n",
    "    cost = -((y_train * torch.log(hx)) + ((1 - y_train) * torch.log(1-hx))).mean()\n",
    "    # cost = F.binary_cross_entorpy(hx, y_train) 와 동일\n",
    "    \n",
    "    # 3. 최적화 (loss, cost function을 미분하고, \n",
    "    # 경사타고 내려오면서 w, b 업데이트)\n",
    "    optimizer.zero_grad()  # 누적 방지\n",
    "    cost.backward()  # loss function 미분\n",
    "    optimizer.step()  # SGD 작동 : lr 만큼 내려가면서 w,b 업데이트\n",
    "    \n",
    "    # 4. loss 값 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch:4d}/{nb_epochs}, cost: {cost.item():.6f}\")\n",
    "    \n",
    "print(f\"w : {w}\\nb : {b}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18816be8-045f-4c9d-ae27-314b24257af9",
   "metadata": {},
   "source": [
    "# inference\n",
    "- model parameter를 이용한 inference\n",
    "- training dataset에 대해서 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "752f793c-ce72-404c-b840-1ec02e398d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.4359e-05],\n",
       "        [1.6836e-02],\n",
       "        [2.0150e-02],\n",
       "        [9.7645e-01],\n",
       "        [9.9951e-01],\n",
       "        [9.9994e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(w)+b)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7d3bc-ca64-4913-b9bc-c597611f7c9d",
   "metadata": {},
   "source": [
    "## sigmoid의 출력값이 0.5 이상이면 1, 아니면 0으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccabfcae-89a1-42d7-b7e5-e95eecd83b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = []\n",
    "for i in list(hypothesis):\n",
    "    if i >= 0.5:\n",
    "        pred.append(1)\n",
    "    else: \n",
    "        pred.append(0)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "374ee6fb-1921-4fb1-b7f7-780edb5a89ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위 셀을 아래와 같이도 가능함\n",
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11155c-fc51-480b-b4de-fd539e1cb542",
   "metadata": {},
   "source": [
    "---\n",
    "# pytorch로 구현하기\n",
    "```python\n",
    "nn.Sequential()  # nn.Module 층을 차례로 쌓을 수 있도록 함\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d6f07ea-ae15-4bd4-9263-38a4c9e6b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 1),  # input Dim 2, output Dim 1\n",
    "    nn.Sigmoid()  # 출력은 시그모이드 결과\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcded6f4-cd16-4a02-a736-6968292bd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54727da4-2e12-4cf0-8634-8736b0fb1eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000, cost: 0.006956, Accuracy:  100.00%\n",
      "Epoch  200/1000, cost: 0.006533, Accuracy:  100.00%\n",
      "Epoch  400/1000, cost: 0.006159, Accuracy:  100.00%\n",
      "Epoch  600/1000, cost: 0.005825, Accuracy:  100.00%\n",
      "Epoch  800/1000, cost: 0.005526, Accuracy:  100.00%\n",
      "Epoch 1000/1000, cost: 0.005256, Accuracy:  100.00%\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        \n",
    "        # 실제 y_train 값(GT)과 예측된 값을 비교한 결과\n",
    "        correct_pred = prediction == y_train\n",
    "        accuracy = correct_pred.sum().item() / len(correct_pred)  # True=1이므로 맞춘 개수\n",
    "        # correct_pred.sum() 하면 tensor(6) 형태로 나오기 때문에 그 값(6)만 가져오기 위해 item() 붙여줌\n",
    "        \n",
    "        print(f\"Epoch {epoch:4d}/{nb_epochs}, cost: {cost.item():.6f},\"\n",
    "              f\" Accuracy: {accuracy * 100: 3.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debf9e0-6155-48a0-a10d-46765f0356d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
