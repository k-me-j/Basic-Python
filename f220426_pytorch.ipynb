{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aefd4a5-2a9b-439d-a490-188e26a8a691",
   "metadata": {},
   "source": [
    "# Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6039ed20-2902-43be-9825-75c720bd95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # neural net 사용하기 위함\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim  # optimizer 선택하기 위함\n",
    " \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea3f32d-b9f3-4362-98f6-84866ade2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값과 출력값\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92a464-9d81-45e7-ad78-0dabc251129a",
   "metadata": {},
   "source": [
    "# ▶ H(x) = Wx + b : w값과 b값을 찾기 위함\n",
    "\n",
    "model 선언을 하고, 초기화, 단순 선형회귀,  \n",
    "입력 dimension 1, 출력 dimension 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e562c-c4da-495a-aa89-1bbd08c0e72d",
   "metadata": {},
   "source": [
    "### ▷ model 생성하게 되면 model의 값은?\n",
    "model parameters : w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4808707-b765-4622-9358-9855025cee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.3548]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.5491], requires_grad=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(1, 1)  # 입력 형태\n",
    "list(model.parameters())  # 처음엔 랜덤한 값 출력됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab012de4-a502-4f8d-abad-65aa16d496ed",
   "metadata": {},
   "source": [
    "# ▶ 최적화를 하기 위한 방법 정의\n",
    "- optimizer로 경사하강법(SGD) 사용\n",
    "- ```W := W - lr(gradient)```\n",
    "- learning rate 설정 : ```lr=0.01```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68647dc5-f3b4-4523-b7ff-c83c4d57fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6737b84a-7e17-4829-80c5-58fc6d9695e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost : 9.318817138671875\n",
      "Cost : 0.10082312673330307\n",
      "Cost : 0.06230254843831062\n",
      "Cost : 0.03849911317229271\n",
      "Cost : 0.023790106177330017\n",
      "Cost : 0.014700808562338352\n",
      "Cost : 0.00908423401415348\n",
      "Cost : 0.005613468587398529\n",
      "Cost : 0.0034687903244048357\n",
      "Cost : 0.0021435071248561144\n",
      "Cost : 0.0013245693407952785\n",
      "Cost : 0.00081849773414433\n",
      "Cost : 0.0005057883099652827\n",
      "Cost : 0.00031254664645530283\n",
      "Cost : 0.00019313330994918942\n",
      "Cost : 0.00011934619396924973\n",
      "Cost : 7.374708366114646e-05\n",
      "Cost : 4.557210559141822e-05\n",
      "Cost : 2.8160442525404505e-05\n",
      "Cost : 1.740245170367416e-05\n",
      "Cost : 1.0753098649729509e-05\n",
      "Final Weight, Bias : Parameter containing:\n",
      "tensor([[1.9962]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0086], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 현재 전체 데이터 셋 x_train = (1, 2, 3)에 대해 경사하강법을 얼마나 할래? 적용해보기\n",
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # H(x) = Wx + b를 계산\n",
    "    # w, b는 초기 랜덤값 pred vs. 실제값하고 얼마나 차이가 있냐를 계산\n",
    "    pred = model(x_train) \n",
    "    \n",
    "    # cost 계산 = Loss Function, Error 값을 계산\n",
    "    cost = F.mse_loss(pred, y_train)  # (찐 - pred) 한 오차값을 제곱해서 mean square 구함\n",
    "    \n",
    "    # cost를 기준으로 weight, bias 값을 업데이트\n",
    "    optimizer.zero_grad()  # pytorch에서 이걸 사용해야 계산된 값이 누적되지 않음. 이걸 써야 값이 갱신됨\n",
    "    # -> w, b 값 업데이트\n",
    "    \n",
    "    # loss 값을 줄이기 : 아래 두 줄은 함께 써주기\n",
    "    cost.backward()  # backward하면서 위에서 구한 weight값을 조정.\n",
    "    optimizer.step()  # w, b값이 업데이트\n",
    "    \n",
    "    # 100번마다 log 값 출력 : 변경되는 w, b\n",
    "    if epoch % 100 == 0:\n",
    "        weightBias = list(model.parameters())  # 마지막값 출력 해보고 싶은데 그러려면 값을 저장해둬야 함. 그래서 생성한 변수\n",
    "        print(f'Cost : {cost.item()}')  # Cost.item() : w, b 쌍으로 나옴\n",
    "\n",
    "print(f'Final Weight, Bias : {weightBias[0]}, {weightBias[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c845a8b-ac88-4670-a610-8a51b0157afc",
   "metadata": {},
   "source": [
    "---\n",
    "# ㄱㄱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddf941-1cba-4136-8daa-9b9ee4baea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1], [2, 1], [3, 1]])  # 3x2 Matrix\n",
    "b = np.array([2, 4, 6])  # 3x1 Vector\n",
    "c = np.matmul(np.matmul(np.linalg.inv(np.matmul(A.T, A)), A.T), b)  # projection = 추정값\n",
    "# linalg : linear algorithm\n",
    "\n",
    "# print(c)  # Wx+b에서 weight값과 bias 값에 해당"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37274de1-bd11-4f15-9ec5-c6a384d70689",
   "metadata": {},
   "source": [
    "c = np.matmul(np.matmul(np.linalg.inv(np.matmul(A.T, A)), A.T), b)  # projection = 추정값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f7c13b-a680-4fe4-8a0b-7bb16c979f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.linalg.inv(np.matmul(A.T, A))  # 여기까진 문제 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe27282-12fc-4fa3-938d-8a9c3f6de5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.matmul(c, A.T)  # 여기서부터 kernel died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895266f-af75-4a92-95ef-b733cc1f5b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
